{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/your_local_path_to/StreamForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-26 01:08:10,972] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.mm_utils import process_anyres_image,tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria, process_anyres_video_nopad\n",
    "\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "\n",
    "\n",
    "from transformers import AutoConfig\n",
    "from llava.video_utils import VIDEO_READER_FUNCS\n",
    "\n",
    "\n",
    "def split_list(lst, n):\n",
    "    \"\"\"Split a list into n (roughly) equal-sized chunks\"\"\"\n",
    "    chunk_size = math.ceil(len(lst) / n)  # integer division\n",
    "    return [lst[i : i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "\n",
    "\n",
    "def get_chunk(lst, n, k):\n",
    "    chunks = split_list(lst, n)\n",
    "    return chunks[k]\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse command-line arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Define the command-line arguments\n",
    "#     parser.add_argument(\"--video_path\", help=\"Path to the video files.\", default=\"/mnt/petrelfs/zengxiangyu/OpenSource/Backup/fg-videochat/download/demo_video/legendof1900.mp4\")\n",
    "#     parser.add_argument(\"--prompt\", default=\"describe this video in detail.\", type=str) \n",
    "    \n",
    "    \n",
    "    parser.add_argument(\"--output_dir\", default=\"./work_dirs/video_demo/\", help=\"Directory to save the model results JSON.\")\n",
    "    parser.add_argument(\"--output_name\",default=\"pred\" , help=\"Name of the file for storing results JSON.\")\n",
    "    parser.add_argument(\"--model-path\", type=str, default=\"/your_local_path_to/StreamForest/ckpt/StreamForest-Qwen2-7B_Siglip\")\n",
    "    parser.add_argument(\"--inference_device\", type=str, default=\"cuda:0\")\n",
    "    parser.add_argument(\"--model-base\", type=str, default=None)\n",
    "    parser.add_argument(\"--conv-mode\", type=str, default=\"qwen_2\")\n",
    "    parser.add_argument(\"--chunk-idx\", type=int, default=0)\n",
    "    parser.add_argument(\"--max_num_frames\", type=int, default=4096)\n",
    "    parser.add_argument(\"--load_8bit\",  type=lambda x: (str(x).lower() == 'true'), default=False)\n",
    "    parser.add_argument(\"--force_sample\", type=lambda x: (str(x).lower() == 'true'), default=False)\n",
    "    parser.add_argument(\"--time_msg\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--llm_type\", type=str, default=\"\")\n",
    "    parser.add_argument(\"--attn_implementation\", type=str, default=\"flash_attention_2\")\n",
    "    parser.add_argument(\"--use_hd\", type=bool, default=False)\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llava_model_args = {\n",
    "}\n",
    "# overwrite_config = {}\n",
    "# mm_projector_type=None\n",
    "\n",
    "\n",
    "\n",
    "# mm_projector_type=\"tome196_memory_1k\"\n",
    "\n",
    "\n",
    "# if mm_projector_type is not None and mm_projector_type!=\"\":\n",
    "#     print(\"<<< warning >>> replace projector with: \", mm_projector_type)\n",
    "#     overwrite_config[\"mm_projector_type\"] = mm_projector_type\n",
    "    \n",
    "    \n",
    "# llava_model_args[\"overwrite_config\"] = overwrite_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded LLaVA model: /your_local_path_to/StreamForest/ckpt/StreamForest-Qwen2-7B_Siglip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
      "You are using a model of type qwen2 to instantiate a model of type llava_qwen. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vision tower: /mnt/petrelfs/share/videointern/siglip/siglip-so400m-patch14-384\n",
      "<<<mm_projector time_pos_embedding_window>>> :  512\n",
      "pos_emb shape torch.Size([512, 1, 1, 1152])\n",
      "<<< self.sim_weight_g:  0.4 >>>\n",
      "<<< self.time_weight_a:  0.2 >>>\n",
      "<<< self.merge_weight_b:  0.4 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.embeddings.patch_embedding.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.embeddings.patch_embedding.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.embeddings.position_embedding.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.0.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.1.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.2.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.3.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.4.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.5.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.6.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.7.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.8.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.9.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.10.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.11.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.12.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.13.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.14.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.15.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.16.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.17.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.18.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.19.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.20.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.21.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.22.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.23.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.24.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.25.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.self_attn.k_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.self_attn.v_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.self_attn.q_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.self_attn.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.self_attn.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.layer_norm1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.layer_norm1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.layer_norm2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.encoder.layers.26.layer_norm2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.post_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.post_layernorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.probe: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.attention.in_proj_weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.attention.in_proj_bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.attention.out_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.attention.out_proj.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.layernorm.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.mlp.fc1.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.mlp.fc1.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.mlp.fc2.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/torch/nn/modules/module.py:2025: UserWarning: for vision_model.head.mlp.fc2.bias: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)\n",
      "  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2f85419fb748edba029d652d63e348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Class: LlavaQwenForCausalLM\n",
      "Model tensor type:  torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model_name = get_model_name_from_path(args.model_path)\n",
    "# Set model configuration parameters if they exist\n",
    "model_name += args.llm_type\n",
    "cfg_pretrained = AutoConfig.from_pretrained(args.model_path, trust_remote_code=True,)\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(args.model_path, args.model_base, model_name, load_8bit=args.load_8bit, multimodal=True, trust_remote_code=True, attn_implementation=args.attn_implementation, **llava_model_args)\n",
    "model.to(torch.float16)\n",
    "\n",
    "print(\"Model tensor type: \", model.dtype)\n",
    "\n",
    "# import pdb;pdb.set_trace()\n",
    "if getattr(model.config, \"force_sample\", None) is not None:\n",
    "    args.force_sample = model.config.force_sample\n",
    "else:\n",
    "    args.force_sample = False\n",
    "\n",
    "# import pdb;pdb.set_trace()\n",
    "\n",
    "if getattr(model.config, \"add_time_instruction\", None) is not None:\n",
    "    args.add_time_instruction = model.config.add_time_instruction\n",
    "else:\n",
    "    args.add_time_instruction = False\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(video_path, args, question_time=0):\n",
    "    if os.path.isdir(video_path):\n",
    "        media_dict = {'video_read_type': 'img'}\n",
    "    else:\n",
    "        media_dict = {'video_read_type': 'decord'}\n",
    "\n",
    "    if type(video_path) != str:\n",
    "        assert len(video_path) == 1, video_path\n",
    "        video_path = video_path[0]\n",
    "\n",
    "    if question_time>0:\n",
    "        clip = [0, question_time]\n",
    "    else:\n",
    "        clip = None\n",
    "    \n",
    "    if 's3://' in video_path:\n",
    "        from petrel_client.client import Client\n",
    "        client = Client(conf_path='~/petreloss.conf')\n",
    "    else:\n",
    "        client = None\n",
    "    \n",
    "    max_frames_num = args.max_num_frames\n",
    "    \n",
    "    if 'fps' in media_dict:\n",
    "        frames, frame_indices, fps, duration = VIDEO_READER_FUNCS[media_dict['video_read_type']](video_path=video_path, num_frames=max_frames_num, sample='dynamic_fps1', fix_start=None, min_num_frames=4, max_num_frames=max_frames_num, client=client, clip=clip, local_num_frames=1, fps=media_dict['fps'])\n",
    "    else:\n",
    "        frames, frame_indices, fps, duration = VIDEO_READER_FUNCS[media_dict['video_read_type']](video_path=video_path, num_frames=max_frames_num, sample='dynamic_fps1', fix_start=None, min_num_frames=4, max_num_frames=max_frames_num, client=client, clip=clip, local_num_frames=1)\n",
    "    sec = [str(round(f / fps, 1)) for f in frame_indices]\n",
    "\n",
    "    if args.time_msg is not None and sec is not None:\n",
    "        if args.time_msg == 'short':\n",
    "            msg = f\"\\nThe video lasts for {duration:.2f} seconds, and {len(sec)} frames are uniformly sampled from it. \"\n",
    "        elif args.time_msg == 'short_online':\n",
    "            msg = f\"\\nThe video segment contains {len(sec)} frames sampled from the past {(float(sec[-1])-float(sec[0])):.1f} seconds ago up to the present moment. \"\n",
    "        elif args.time_msg == 'short_online_v2':\n",
    "            msg = f\"\\nThe video contains {len(sec)} frames sampled from the past {(float(sec[-1])-float(sec[0])):.1f} seconds ago ({float(sec[0]):.1f}s of the entire video) up to the present moment ({float(sec[-1]):.1f}s of the entire video). \"\n",
    "        elif args.time_msg == 'short_online_per_frame':\n",
    "            msg_overall = f\"\\nThe video contains {len(sec)} frames sampled from the past {(float(sec[-1])-float(sec[0])):.1f} seconds ago ({float(sec[0]):.1f}s of the entire video) up to the present moment ({float(sec[-1]):.1f}s of the entire video). \"\n",
    "            msg_per_frame =  ''.join([f\"[TIME_MSG_PER_FRAME]{sec_time} seconds\" for sec_time in sec])+\"[TIME_MSG_PER_FRAME]\"\n",
    "            msg = msg_overall + msg_per_frame\n",
    "        else:\n",
    "            msg = f\"\\nThe video lasts for {duration:.2f} seconds, and {len(sec)} frames are uniformly sampled at {', '.join(sec)} seconds. \"\n",
    "    else:\n",
    "        msg = \"\"\n",
    "\n",
    "    return frames, msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = args.output_name\n",
    "answers_file = os.path.join(args.output_dir, f\"{output_name}.json\")\n",
    "ans_file = open(answers_file, \"w\")\n",
    "import time\n",
    "import torch.profiler\n",
    "\n",
    "def run_inference(args, video_path, question, question_time=0):\n",
    "    \"\"\"\n",
    "    Run inference on a demo video using VideoChat-Next model.\n",
    "\n",
    "    Args:\n",
    "        args: Command-line arguments.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    if hasattr(model.config, \"frame_aspect_ratio\"):\n",
    "        frame_aspect_ratio = model.config.frame_aspect_ratio\n",
    "    else:\n",
    "        frame_aspect_ratio = \"\"\n",
    "\n",
    "    # import pdb;pdb.set_trace()\n",
    "\n",
    "    print(\"video_path:\", video_path)\n",
    "    sample_set = {}\n",
    "    sample_set[\"Q\"] = question\n",
    "    sample_set[\"video_name\"] = video_path\n",
    "\n",
    "\n",
    "    # Check if the video exists\n",
    "    # if os.path.exists(video_path) :\n",
    "    assert 's3://' in video_path or os.path.exists(video_path), video_path\n",
    "\n",
    "    frames, time_msg  = load_video(video_path, args, question_time)\n",
    "    print(\"len(frames):\", len(frames))\n",
    "    image_sizes = [frames[0].shape[:2]]\n",
    "    print(\"image_sizes:\", image_sizes)\n",
    "\n",
    "\n",
    "    frames = image_processor.preprocess(frames, return_tensors=\"pt\")[\"pixel_values\"].to(dtype=model.dtype).cuda(args.inference_device)\n",
    "\n",
    "    print(\"input frames:\", frames.shape)\n",
    "    \n",
    "    video = [frames]\n",
    "\n",
    "    # try:\n",
    "    # Run inference on the video and add the output to the list\n",
    "    qs = question\n",
    "    if args.time_msg != \"\":\n",
    "        qs = f'{time_msg.strip()}\\n{qs}'\n",
    "        \n",
    "    if model.config.mm_use_im_start_end:\n",
    "        qs = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + \"\\n\" + qs\n",
    "    else:\n",
    "        qs = DEFAULT_IMAGE_TOKEN + \"\\n\" + qs\n",
    "\n",
    "    \n",
    "    print(f\"Question: {qs}\")\n",
    "    conv = conv_templates[args.conv_mode].copy()\n",
    "    conv.append_message(conv.roles[0], qs)\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "    prompt = conv.get_prompt()\n",
    "\n",
    "    input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).cuda(args.inference_device)\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        if \"qwen\" in tokenizer.name_or_path.lower():\n",
    "            print(\"Setting pad token to bos token for qwen model.\")\n",
    "            tokenizer.pad_token_id = 151643\n",
    "\n",
    "    attention_masks = input_ids.ne(tokenizer.pad_token_id).long().cuda(args.inference_device)\n",
    "\n",
    "    stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "    keywords = [stop_str]\n",
    "    stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        if \"mistral\" not in cfg_pretrained._name_or_path.lower():\n",
    "            output_ids = model.generate_online(\n",
    "                inputs=input_ids,\n",
    "                images=video,\n",
    "                attention_mask=attention_masks,\n",
    "                modalities=[\"video\"],\n",
    "                image_sizes=image_sizes,\n",
    "                do_sample=False,\n",
    "                temperature=0.0,\n",
    "                max_new_tokens=1,\n",
    "                num_beams=1,\n",
    "                use_cache=True,\n",
    "                stopping_criteria=[stopping_criteria]\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            output_ids = model.generate(inputs=input_ids, images=video, attention_mask=attention_masks, modalities=\"video\", do_sample=False, temperature=0.0, max_new_tokens=1024, top_p=0.1, num_beams=1, use_cache=True)\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"\\n <<< Total inference time: {elapsed_time:.3f} seconds >>> \\n\")\n",
    "    print(f\"\\n <<< Total average speed: {video[0].shape[0]/elapsed_time:.3f} fps >>> \\n\")\n",
    "    \n",
    "    outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "    \n",
    "    print(f\"Question: {prompt}\\n\")\n",
    "    print(f\"Response: {outputs}\\n\")\n",
    "\n",
    "    # import pdb;pdb.set_trace()\n",
    "    if \"mistral\" not in cfg_pretrained._name_or_path.lower():\n",
    "        if outputs.endswith(stop_str):\n",
    "            outputs = outputs[: -len(stop_str)]\n",
    "\n",
    "    outputs = outputs.strip()\n",
    "\n",
    "    sample_set[\"pred\"] = outputs\n",
    "    ans_file.write(json.dumps(sample_set, ensure_ascii=False) + \"\\n\")\n",
    "    ans_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_path: demo/video/Forrest_Gump.mp4\n",
      "len(frames): 601\n",
      "image_sizes: [(320, 752)]\n",
      "input frames: torch.Size([601, 3, 384, 384])\n",
      "Question: <image>\n",
      "Please describe the content of the video in detail.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/mnt/petrelfs/zengxiangyu/.conda/envs/videochat-flash/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:612: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <<< LLM inference time: 0.157 seconds >>> \n",
      "result at frame 0 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.028 seconds >>> \n",
      "result at frame 1 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.028 seconds >>> \n",
      "result at frame 2 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.046 seconds >>> \n",
      "result at frame 3 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.032 seconds >>> \n",
      "result at frame 4 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.032 seconds >>> \n",
      "result at frame 5 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.032 seconds >>> \n",
      "result at frame 6 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.031 seconds >>> \n",
      "result at frame 7 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.032 seconds >>> \n",
      "result at frame 8 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.032 seconds >>> \n",
      "result at frame 9 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.032 seconds >>> \n",
      "result at frame 10 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.038 seconds >>> \n",
      "result at frame 11 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.038 seconds >>> \n",
      "result at frame 12 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.038 seconds >>> \n",
      "result at frame 13 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.038 seconds >>> \n",
      "result at frame 14 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.038 seconds >>> \n",
      "result at frame 15 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.038 seconds >>> \n",
      "result at frame 16 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.039 seconds >>> \n",
      "result at frame 17 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.039 seconds >>> \n",
      "result at frame 18 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.045 seconds >>> \n",
      "result at frame 19 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.045 seconds >>> \n",
      "result at frame 20 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.045 seconds >>> \n",
      "result at frame 21 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.045 seconds >>> \n",
      "result at frame 22 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.047 seconds >>> \n",
      "result at frame 23 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.047 seconds >>> \n",
      "result at frame 24 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.048 seconds >>> \n",
      "result at frame 25 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.049 seconds >>> \n",
      "result at frame 26 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.055 seconds >>> \n",
      "result at frame 27 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.055 seconds >>> \n",
      "result at frame 28 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.056 seconds >>> \n",
      "result at frame 29 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.056 seconds >>> \n",
      "result at frame 30 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.056 seconds >>> \n",
      "result at frame 31 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.056 seconds >>> \n",
      "result at frame 32 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.057 seconds >>> \n",
      "result at frame 33 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.057 seconds >>> \n",
      "result at frame 34 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.065 seconds >>> \n",
      "result at frame 35 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.065 seconds >>> \n",
      "result at frame 36 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.065 seconds >>> \n",
      "result at frame 37 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.065 seconds >>> \n",
      "result at frame 38 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.066 seconds >>> \n",
      "result at frame 39 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.066 seconds >>> \n",
      "result at frame 40 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.067 seconds >>> \n",
      "result at frame 41 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.067 seconds >>> \n",
      "result at frame 42 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.069 seconds >>> \n",
      "result at frame 43 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.070 seconds >>> \n",
      "result at frame 44 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.071 seconds >>> \n",
      "result at frame 45 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.071 seconds >>> \n",
      "result at frame 46 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.071 seconds >>> \n",
      "result at frame 47 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.071 seconds >>> \n",
      "result at frame 48 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.072 seconds >>> \n",
      "result at frame 49 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.072 seconds >>> \n",
      "result at frame 50 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.084 seconds >>> \n",
      "result at frame 51 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.084 seconds >>> \n",
      "result at frame 52 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.084 seconds >>> \n",
      "result at frame 53 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.085 seconds >>> \n",
      "result at frame 54 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.085 seconds >>> \n",
      "result at frame 55 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 56 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 57 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 58 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 59 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 60 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 61 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.092 seconds >>> \n",
      "result at frame 62 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 63 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 64 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 65 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 66 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 67 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 68 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 69 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 70 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 71 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 72 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 73 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 74 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 75 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 76 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 77 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.092 seconds >>> \n",
      "result at frame 78 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 79 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 80 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 81 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 82 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.092 seconds >>> \n",
      "result at frame 83 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 84 : tensor([[785]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 85 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 86 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 87 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 88 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 89 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 90 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 91 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 92 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 93 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 94 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 95 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 96 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 97 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 98 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.092 seconds >>> \n",
      "result at frame 99 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 100 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 101 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 102 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 103 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 104 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 105 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 106 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 107 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 108 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 109 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 110 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 111 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 112 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 113 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 114 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 115 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 116 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 117 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 118 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 119 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 120 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 121 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 122 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 123 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 124 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 125 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.085 seconds >>> \n",
      "result at frame 126 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 127 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 128 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 129 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 130 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 131 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 132 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 133 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 134 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 135 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 136 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 137 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 138 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 139 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 140 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 141 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 142 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.085 seconds >>> \n",
      "result at frame 143 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 144 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 145 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 146 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 147 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 148 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 149 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 150 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 151 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 152 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 153 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 154 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 155 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 156 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 157 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 158 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 159 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 160 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 161 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 162 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 163 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 164 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 165 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 166 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 167 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 168 : tensor([[785]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 169 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 170 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 171 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 172 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 173 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 174 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 175 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 176 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 177 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 178 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 179 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 180 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 181 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 182 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 183 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 184 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 185 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 186 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.090 seconds >>> \n",
      "result at frame 187 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 188 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 189 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 190 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 191 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 192 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 193 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 194 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 195 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 196 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 197 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 198 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 199 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 200 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 201 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 202 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 203 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 204 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.085 seconds >>> \n",
      "result at frame 205 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 206 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 207 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 208 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 209 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 210 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 211 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 212 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 213 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 214 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 215 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 216 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 217 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 218 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 219 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 220 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 221 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 222 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 223 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 224 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 225 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 226 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 227 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 228 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 229 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 230 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 231 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 232 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 233 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 234 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 235 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 236 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 237 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 238 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 239 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 240 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 241 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 242 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 243 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 244 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 245 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 246 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 247 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 248 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 249 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 250 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 251 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 252 : tensor([[785]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 253 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 254 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.085 seconds >>> \n",
      "result at frame 255 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 256 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 257 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 258 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 259 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 260 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.090 seconds >>> \n",
      "result at frame 261 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 262 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 263 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 264 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.085 seconds >>> \n",
      "result at frame 265 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 266 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 267 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 268 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 269 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 270 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 271 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 272 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.094 seconds >>> \n",
      "result at frame 273 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 274 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.085 seconds >>> \n",
      "result at frame 275 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 276 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 277 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 278 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 279 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 280 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 281 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 282 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 283 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 284 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 285 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.094 seconds >>> \n",
      "result at frame 286 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 287 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 288 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 289 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 290 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 291 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 292 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 293 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 294 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 295 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 296 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 297 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 298 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 299 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 300 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 301 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 302 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 303 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 304 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 305 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 306 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 307 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 308 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 309 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 310 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 311 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 312 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 313 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 314 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 315 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 316 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 317 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 318 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 319 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 320 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 321 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 322 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 323 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 324 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 325 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 326 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 327 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 328 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 329 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 330 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 331 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 332 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 333 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 334 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 335 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 336 : tensor([[785]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 337 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 338 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 339 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 340 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 341 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 342 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 343 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 344 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 345 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 346 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 347 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 348 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 349 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 350 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 351 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 352 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 353 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 354 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 355 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 356 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 357 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 358 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.094 seconds >>> \n",
      "result at frame 359 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 360 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 361 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 362 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 363 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 364 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 365 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 366 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 367 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 368 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 369 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 370 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.091 seconds >>> \n",
      "result at frame 371 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 372 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 373 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 374 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 375 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 376 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 377 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 378 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 379 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 380 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 381 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 382 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 383 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 384 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 385 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 386 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 387 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 388 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 389 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 390 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 391 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 392 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 393 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 394 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 395 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 396 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 397 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 398 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 399 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 400 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 401 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 402 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 403 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.094 seconds >>> \n",
      "result at frame 404 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 405 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 406 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 407 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 408 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.095 seconds >>> \n",
      "result at frame 409 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 410 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 411 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 412 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 413 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 414 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 415 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 416 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 417 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 418 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 419 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 420 : tensor([[785]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 421 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 422 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 423 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 424 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 425 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 426 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 427 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 428 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 429 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 430 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 431 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 432 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 433 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 434 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 435 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 436 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 437 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 438 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 439 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 440 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 441 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 442 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 443 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 444 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 445 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 446 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 447 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 448 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 449 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 450 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 451 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 452 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 453 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 454 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 455 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 456 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 457 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 458 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 459 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 460 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 461 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 462 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 463 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 464 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 465 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 466 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 467 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 468 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 469 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 470 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 471 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 472 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 473 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 474 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 475 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 476 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 477 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 478 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 479 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 480 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 481 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 482 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 483 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 484 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 485 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.094 seconds >>> \n",
      "result at frame 486 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 487 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.094 seconds >>> \n",
      "result at frame 488 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 489 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 490 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 491 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 492 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.094 seconds >>> \n",
      "result at frame 493 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 494 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 495 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 496 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 497 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 498 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 499 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 500 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 501 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 502 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 503 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 504 : tensor([[785]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 505 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 506 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 507 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 508 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 509 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 510 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 511 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 512 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 513 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 514 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 515 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 516 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 517 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 518 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 519 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 520 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 521 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 522 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 523 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 524 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 525 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 526 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 527 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 528 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 529 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 530 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 531 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 532 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 533 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 534 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 535 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 536 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 537 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 538 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 539 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 540 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 541 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 542 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 543 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 544 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 545 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 546 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 547 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 548 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 549 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 550 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 551 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 552 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 553 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 554 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 555 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 556 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 557 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 558 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 559 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 560 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 561 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 562 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 563 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 564 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 565 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 566 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 567 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 568 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 569 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 570 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 571 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 572 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 573 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 574 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 575 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 576 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 577 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 578 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 579 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 580 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 581 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 582 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 583 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 584 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 585 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 586 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 587 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.086 seconds >>> \n",
      "result at frame 588 : tensor([[785]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 589 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 590 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 591 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 592 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 593 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 594 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 595 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 596 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.089 seconds >>> \n",
      "result at frame 597 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.093 seconds >>> \n",
      "result at frame 598 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.087 seconds >>> \n",
      "result at frame 599 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< LLM inference time: 0.088 seconds >>> \n",
      "result at frame 600 : tensor([[785]], device='cuda:0')\n",
      "\n",
      " <<< Total inference time: 60.384 seconds >>> \n",
      "\n",
      "\n",
      " <<< Total average speed: 9.953 fps >>> \n",
      "\n",
      "Question: <|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "<image>\n",
      "Please describe the content of the video in detail.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "Response: The\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# StreamForest\n",
    "video_path = \"demo/video/Forrest_Gump.mp4\"\n",
    "question= \"Please describe the content of the video in detail.\"\n",
    "# question= \"Is there a man in black in the picture?\"\n",
    "\n",
    "question_time=600\n",
    "run_inference(args,video_path,question,question_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
